{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7GNddilc--g",
        "outputId": "e44c13ac-593c-4886-b799-e7f6c159cc9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         x0        x1   x2   x3   x4   x5   x6     x0 x1     x0 x2     x0 x3  \\\n",
            "0  1.196369 -0.784395  0.0  1.0  0.0  0.0  1.0 -0.938426  0.000000  1.196369   \n",
            "1 -0.418010 -0.923715  1.0  0.0  0.0  1.0  0.0  0.386122 -0.418010 -0.000000   \n",
            "2 -1.104442 -1.074922  0.0  1.0  0.0  0.0  1.0  1.187190 -0.000000 -1.104442   \n",
            "3  0.039564 -1.723908  0.0  1.0  0.0  1.0  0.0 -0.068205  0.000000  0.039564   \n",
            "4 -0.545476 -0.825825  1.0  0.0  0.0  1.0  0.0  0.450468 -0.545476 -0.000000   \n",
            "\n",
            "   ...  x2 x3  x2 x4  x2 x5  x2 x6  x3 x4  x3 x5  x3 x6  x4 x5  x4 x6  x5 x6  \n",
            "0  ...    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
            "1  ...    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
            "3  ...    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
            "4  ...    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "         x0        x1   x2   x3   x4   x5   x6     x0 x1     x0 x2     x0 x3  \\\n",
            "0 -0.405314  0.474580  0.0  1.0  0.0  1.0  0.0 -0.192354 -0.000000 -0.405314   \n",
            "1  0.843222  0.211368  1.0  0.0  0.0  1.0  0.0  0.178230  0.843222  0.000000   \n",
            "2  0.000000 -0.968654  0.0  1.0  0.0  0.0  1.0 -0.000000  0.000000  0.000000   \n",
            "3 -0.628043  0.789476  0.0  1.0  0.0  0.0  1.0 -0.495825 -0.000000 -0.628043   \n",
            "4 -1.466345  0.240431  0.0  0.0  1.0  0.0  1.0 -0.352556 -0.000000 -0.000000   \n",
            "\n",
            "   ...  x2 x3  x2 x4  x2 x5  x2 x6  x3 x4  x3 x5  x3 x6  x4 x5  x4 x6  x5 x6  \n",
            "0  ...    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
            "1  ...    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
            "3  ...    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
            "4  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Generate a sample dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'num_feature1': np.random.randn(100),\n",
        "    'num_feature2': np.random.randn(100) * 10,\n",
        "    'cat_feature1': np.random.choice(['A', 'B', 'C'], 100),\n",
        "    'cat_feature2': np.random.choice(['X', 'Y'], 100),\n",
        "    'target': np.random.choice([0, 1], 100)\n",
        "})\n",
        "\n",
        "# Introduce some missing values\n",
        "data.loc[::10, 'num_feature1'] = np.nan\n",
        "data.loc[::5, 'cat_feature1'] = np.nan\n",
        "\n",
        "# Splitting the dataset into features and target variable\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Handling missing values\n",
        "# Using SimpleImputer to fill missing values with the mean for numerical features and most frequent value for categorical features\n",
        "\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Applying transformations\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# Feature Engineering - Creating new features\n",
        "# Example: Adding polynomial features\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Converting back to DataFrame for ease of understanding\n",
        "X_train_poly_df = pd.DataFrame(X_train_poly, columns=poly.get_feature_names_out())\n",
        "X_test_poly_df = pd.DataFrame(X_test_poly, columns=poly.get_feature_names_out())\n",
        "\n",
        "# Display the transformed and new features\n",
        "print(X_train_poly_df.head())\n",
        "print(X_test_poly_df.head())\n",
        "\n",
        "# Now you can proceed to use X_train_poly and X_test_poly for training machine learning models\n"
      ]
    }
  ]
}